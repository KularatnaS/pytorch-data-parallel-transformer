2023-12-27 10:49:47,913 INFO    MainThread:21416 [wandb_setup.py:_flush():76] Current SDK version is 0.16.1
2023-12-27 10:49:47,914 INFO    MainThread:21416 [wandb_setup.py:_flush():76] Configure stats pid to 21416
2023-12-27 10:49:47,914 INFO    MainThread:21416 [wandb_setup.py:_flush():76] Loading settings from /home/shash/.config/wandb/settings
2023-12-27 10:49:47,914 INFO    MainThread:21416 [wandb_setup.py:_flush():76] Loading settings from /home/shash/Desktop/pytorch-data-parallel-transformer/wandb/settings
2023-12-27 10:49:47,914 INFO    MainThread:21416 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2023-12-27 10:49:47,915 INFO    MainThread:21416 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-12-27 10:49:47,915 INFO    MainThread:21416 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'train.py', 'program_abspath': '/home/shash/Desktop/pytorch-data-parallel-transformer/train.py', 'program': 'train.py'}
2023-12-27 10:49:47,915 INFO    MainThread:21416 [wandb_setup.py:_flush():76] Applying login settings: {'mode': 'offline'}
2023-12-27 10:49:47,915 INFO    MainThread:21416 [wandb_init.py:_log_setup():524] Logging user logs to /home/shash/Desktop/pytorch-data-parallel-transformer/wandb/offline-run-20231227_104947-lyiuyalo/logs/debug.log
2023-12-27 10:49:47,915 INFO    MainThread:21416 [wandb_init.py:_log_setup():525] Logging internal logs to /home/shash/Desktop/pytorch-data-parallel-transformer/wandb/offline-run-20231227_104947-lyiuyalo/logs/debug-internal.log
2023-12-27 10:49:47,915 INFO    MainThread:21416 [wandb_init.py:init():564] calling init triggers
2023-12-27 10:49:47,916 INFO    MainThread:21416 [wandb_init.py:init():571] wandb.init called with sweep_config: {}
config: {'data_dir': 'data/', 'train_data_dir': 'data/train/', 'val_data_dir': 'data/val/', 'force_build_tokenizer': 'false', 'tokenizer_file': 'tokenizer/tokenizer.json', 'seq_len': 16, 'd_model': 512, 'd_ff': 1024, 'N': 6, 'h': 8, 'dropout': 0.1, 'batch_size': 8, 'lr': 0.0001, 'epochs': 100, 'model_folder': 'weights', 'model_basename': 'tmodel_', 'preload': 'latest', 'experiment_name': 'runs/tmodel'}
2023-12-27 10:49:47,916 INFO    MainThread:21416 [wandb_init.py:init():614] starting backend
2023-12-27 10:49:47,916 INFO    MainThread:21416 [wandb_init.py:init():618] setting up manager
2023-12-27 10:49:47,919 INFO    MainThread:21416 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-12-27 10:49:47,922 INFO    MainThread:21416 [wandb_init.py:init():624] backend started and connected
2023-12-27 10:49:47,934 INFO    MainThread:21416 [wandb_init.py:init():716] updated telemetry
2023-12-27 10:49:47,999 INFO    MainThread:21416 [wandb_init.py:init():749] communicating run to backend with 90.0 second timeout
2023-12-27 10:49:48,003 INFO    MainThread:21416 [wandb_init.py:init():800] starting run threads in backend
2023-12-27 10:49:48,133 INFO    MainThread:21416 [wandb_run.py:_console_start():2233] atexit reg
2023-12-27 10:49:48,133 INFO    MainThread:21416 [wandb_run.py:_redirect():2088] redirect: wrap_raw
2023-12-27 10:49:48,133 INFO    MainThread:21416 [wandb_run.py:_redirect():2153] Wrapping output streams.
2023-12-27 10:49:48,133 INFO    MainThread:21416 [wandb_run.py:_redirect():2178] Redirects installed.
2023-12-27 10:49:48,134 INFO    MainThread:21416 [wandb_init.py:init():841] run started, returning control to user process
2023-12-27 10:50:46,969 WARNING MsgRouterThr:21416 [router.py:message_loop():77] message_loop has been closed
